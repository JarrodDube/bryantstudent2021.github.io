
---
output: 
  html_document:
  pdf_document: default
  word_document: default
title: "Assignment 10: Predictive Modeling - Part 1"
---

***How to do it?***: 

- Open the Rmarkdown file of this assignment ([link](assignment10.Rmd)) in Rstudio. 

- Right under each **question**, insert  a code chunk (you can use the hotkey `Ctrl + Alt + I` to add a code chunk) and code the solution for the question. 

- `Knit` the rmarkdown file (hotkey: `Ctrl + Alt + K`) to export an html.  

-  Publish the html file to your Githiub Page. 

***Submission***: Submit the link on Github of the assignment to Canvas

```{r setup, include=FALSE}
knitr::opts_chunk$set(message = FALSE)
```


-------

1. Use the `Adult Census Income` dataset.  We will predict the income (whether or not it is more than 50k or not) of an adult. Import the dataset.  Partition the data into 80% training and 20% testing.  

```{r}
library(tidyverse)
library(caret)

df = read_csv("C:/Users/student/OneDrive - Bryant University/College/7th Semester/R/adult_census.csv")

df$workclass = as.factor(df$workclass)
df$education = as.factor(df$education)
df$marital.status = as.factor(df$marital.status)
df$occupation = as.factor(df$occupation)
df$relationship = as.factor(df$relationship)
df$race = as.factor(df$race)
df$sex = as.factor(df$sex)
df$native.country = as.factor(df$native.country)
df$income = as.factor(df$income)

set.seed(2020)
splitIndex <- createDataPartition(df$income, p = .80, 
                                  list = FALSE)
df_train <- df[ splitIndex,]
df_test <- df[-splitIndex,]
```

2. Practice Decision Tree.  Do the follows:

  - Use `rpart` package, create a decision tree with maximum depth of 3. 
  
  - Calculate the accuracy of the model on the testing data. Notice that the positive outcome here is not `1` but `>50K` or `<50K`. 
  
  - Plot the tree
  
  - Plot the variable importance by the tree
  
```{r}
library(rpart)
library(rattle)

tree_model <- rpart(income ~ ., data = df_train,
                 control = rpart.control(maxdepth = 3))

pred <- predict(tree_model, df_test, type = "class")
cm <- confusionMatrix(data = pred, reference = df_test$income, positive = ">50K")
cm$overall[1]

fancyRpartPlot(tree_model)

barplot(tree_model$variable.importance)
```

3. Create 3 more trees and compare the testing accuracy of these trees, which tree give the highest testing accuracy.

```{r}
tree_model2 <- rpart(income ~ ., data = df_train,
                 control = rpart.control(maxdepth = 2))

tree_model4 <- rpart(income ~ ., data = df_train,
                 control = rpart.control(maxdepth = 4))

tree_model5 <- rpart(income ~ ., data = df_train,
                 control = rpart.control(maxdepth = 5))

pred2 <- predict(tree_model2, df_test, type = "class")
cm2 <- confusionMatrix(data = pred2, reference = df_test$income, positive = ">50K")
cm2$overall[1]

pred4 <- predict(tree_model4, df_test, type = "class")
cm4 <- confusionMatrix(data = pred4, reference = df_test$income, positive = ">50K")
cm4$overall[1]

pred5 <- predict(tree_model5, df_test, type = "class")
cm5 <- confusionMatrix(data = pred5, reference = df_test$income, positive = ">50K")
cm5$overall[1]
```
The trees with max depth of 4 and 5 stop at 3 because it is the optimal tree.
These two match the original tree's accuracy as the highest.

4. Practice Random Forest.  Do the follows: 

  - Use `randomForest` package, create a random forest of 1000 trees. 
  
  - Calculate the accuracy of the model on the testing data. 
  
  - Plot the variable importance by the forest

```{r}
library(randomForest)

forest_model = randomForest(income ~ ., data=df_train, ntree = 1000)
pred10 <- predict(forest_model, df_test, type = "class")
cm10 <- confusionMatrix(data = pred10, reference = df_test$income, positive = ">50K")
cm10$overall[1]

importance(forest_model)
```

5. Create 3 more forests and compare the testing accuracy of these forests, which forest give the highest testing accuracy.

```{r}
forest_model100 = randomForest(income ~ ., data=df_train, ntree = 100)
pred100 <- predict(forest_model100, df_test, type = "class")
cm100 <- confusionMatrix(data = pred100, reference = df_test$income, positive = ">50K")
cm100$overall[1]

forest_model250 = randomForest(income ~ ., data=df_train, ntree = 250)
pred250 <- predict(forest_model250, df_test, type = "class")
cm250 <- confusionMatrix(data = pred250, reference = df_test$income, positive = ">50K")
cm250$overall[1]

forest_model500 = randomForest(income ~ ., data=df_train, ntree = 500)
pred500 <- predict(forest_model500, df_test, type = "class")
cm500 <- confusionMatrix(data = pred500, reference = df_test$income, positive = ">50K")
cm500$overall[1]
```
The forest with 100 trees has the highest accuracy of these three.

6. What is the best model (in term of testing accuracy) among all models (including trees and forests) you have trained?

```{r}
cm10$overall[1]
```
Random forest with 1000 trees.
