
---
output: 
  html_document:
  pdf_document: default
  word_document: default
title: "Assignment 12: Predictive Modeling - Part 3"
---

***How to do it?***: 

- Open the Rmarkdown file of this assignment ([link](assignment12.Rmd)) in Rstudio. 

- Right under each **question**, insert  a code chunk (you can use the hotkey `Ctrl + Alt + I` to add a code chunk) and code the solution for the question. 

- `Knit` the rmarkdown file (hotkey: `Ctrl + Alt + K`) to export an html.  

-  Publish the html file to your Githiub Page. 

***Submission***: Submit the link on Github of the assignment to Blackboard.

```{r setup, include=FALSE}
knitr::opts_chunk$set(message = FALSE)
```


1. Use the `PimaIndiansDiabetes` dataset. Use 15% data for testing. Use cross-validation with 7 folds to tune random forest `(method='ranger')`.  What are the parameters that produce the greatest accuracy? What is the testing accuracy. 

```{r}
library(mlbench)
library(tidyverse)
library(caret)
data(PimaIndiansDiabetes)
df <- tibble(PimaIndiansDiabetes)

df = drop_na(df)
splitIndex <- createDataPartition(df$diabetes, p = .80, 
                                  list = FALSE)
df_train <- df[ splitIndex,]
df_test <- df[-splitIndex,]

trControl = trainControl(method = "cv",
                         number = 7)
tuneGrid = expand.grid(mtry = 2:4,
                       splitrule = c('gini', 'extratrees'),
                       min.node.size = c(1:10))
forest_ranger <- train(diabetes~., data=df_train, 
                    method = "ranger", 
                    trControl = trControl,
                    tuneGrid = tuneGrid)
plot(forest_ranger)
pred <- predict(forest_ranger, df_test)
cm <- confusionMatrix(data = pred, reference = df_test$diabetes, positive = "pos")
cm$overall[1]
```

2. Use the `PimaIndiansDiabetes` dataset. Go to https://topepo.github.io/caret/available-models.html and pick a classification model.  Tune the classification model using cross-validation of 7 folds. 

```{r}
trControl = trainControl(method = "cv",
                         number = 7)
tuneGrid = expand.grid(mtry = c(2:6))
cforest <- train(diabetes~., data=df_train, 
                    method = "cforest", 
                    trControl = trControl,
                    tuneGrid = tuneGrid)
plot(cforest)
pred <- predict(cforest, df_test)
cm <- confusionMatrix(data = pred, reference = df_test$diabetes, positive = "pos")
cm$overall[1]
```

3. Use the `PimaIndiansDiabetes` dataset. Pick three models at [this link](https://topepo.github.io/caret/available-models.html) to compare using 7-fold cross validation method. Evaluate the accuracy of the final model on the test data. What is the best model?

```{r, warning=FALSE}
trControl = trainControl(method = "cv",
                         number = 7)
tuneGrid = expand.grid(mtry = c(2:6))
parRF <- train(diabetes~., data=df_train, 
                    method = "parRF", 
                    trControl = trControl,
                    tuneGrid = tuneGrid)
plot(parRF)
pred1 <- predict(parRF, df_test)
cm1 <- confusionMatrix(data = pred1, reference = df_test$diabetes, positive = "pos")
cm1$overall[1]

trControl = trainControl(method = "cv",
                         number = 7)
tuneGrid = expand.grid(mtry = c(2:6))
rf <- train(diabetes~., data=df_train, 
                    method = "rf", 
                    trControl = trControl,
                    tuneGrid = tuneGrid)
plot(rf)
pred2 <- predict(rf, df_test)
cm2 <- confusionMatrix(data = pred2, reference = df_test$diabetes, positive = "pos")
cm2$overall[1]

trControl = trainControl(method = "cv",
                         number = 7)
tuneGrid = expand.grid(mtry = c(2:6))
wsrf <- train(diabetes~., data=df_train, 
                    method = "wsrf", 
                    trControl = trControl,
                    tuneGrid = tuneGrid)
plot(wsrf)
pred3 <- predict(wsrf, df_test)
cm3 <- confusionMatrix(data = pred3, reference = df_test$diabetes, positive = "pos")
cm3$overall[1]
```
